{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.misc import lena\n",
    "import cv2\n",
    "import glob\n",
    "import pba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import images , resize them =>  show them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_paths = sorted(glob.glob('../data/*.jpg'))\n",
    "imgs = [cv2.resize(cv2.imread(img_path, cv2.IMREAD_GRAYSCALE), (600, 400)) for img_path in img_paths]\n",
    "mask = np.ones(shape=(400, 600), dtype=np.uint8)\n",
    "mask[300:, 250:380] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find connection between picturs : img1 and img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_matches(img1, kp1, img2, kp2, matches, color=None): \n",
    "    \"\"\"Draws lines between matching keypoints of two images.  \n",
    "    Keypoints not in a matching pair are not drawn.\n",
    "    Places the images side by side in a new image and draws circles \n",
    "    around each keypoint, with line segments connecting matching pairs.\n",
    "    You can tweak the r, thickness, and figsize values as needed.\n",
    "    Args:\n",
    "        img1: An openCV image ndarray in a grayscale or color format.\n",
    "        kp1: A list of cv2.KeyPoint objects for img1.\n",
    "        img2: An openCV image ndarray of the same format and with the same \n",
    "        element type as img1.\n",
    "        kp2: A list of cv2.KeyPoint objects for img2.\n",
    "        matches: A list of DMatch objects whose trainIdx attribute refers to \n",
    "        img1 keypoints and whose queryIdx attribute refers to img2 keypoints.\n",
    "        color: The color of the circles and connecting lines drawn on the images.  \n",
    "        A 3-tuple for color images, a scalar for grayscale images.  If None, these\n",
    "        values are randomly generated.  \n",
    "    \"\"\"\n",
    "    # We're drawing them side by side.  Get dimensions accordingly.\n",
    "    # Handle both color and grayscale images.\n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "        \n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 2\n",
    "    if color:\n",
    "        c = color\n",
    "        \n",
    "    for m in matches:\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            \n",
    "        # So the keypoint locs are stored as a tuple of floats.  cv2.line(), like most other things,\n",
    "        # wants locs as a tuple of ints.\n",
    "        #print m, dir(m)\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "        \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match2(img1, img2, kp_mask):\n",
    "    # Initiate ORB detector\n",
    "    orb = cv2.ORB()\n",
    "\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img1, kp_mask)\n",
    "    kp1, des1 = orb.compute(img1, kp)\n",
    "    kp = orb.detect(img2, kp_mask)\n",
    "    kp2, des2 = orb.compute(img2, kp)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(des1.astype(np.float32), des2.astype(np.float32), k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    temp = mask.ravel().tolist()\n",
    "\n",
    "    matches_filtered = [g for g, t in zip(good, temp) if t]\n",
    "\n",
    "    imgNew = draw_matches(img1, kp1, img2, kp2, matches_filtered)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgNew, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match(imgs, kp_mask):\n",
    "    #\n",
    "    # Initiate ORB detector\n",
    "    #\n",
    "    orb = cv2.ORB()\n",
    "\n",
    "    kps = []\n",
    "    descs = []\n",
    "    for img in imgs:\n",
    "        #\n",
    "        # find the keypoints with ORB\n",
    "        #\n",
    "        kp = orb.detect(img, kp_mask)\n",
    "        kp, desc = orb.compute(img, kp)\n",
    "        kps.append(kp)\n",
    "        descs.append(desc)\n",
    "    \n",
    "    kp_mask = np.zeros((len(imgs), len(kps[0])), dtype=np.uint8)\n",
    "    kp_coords = np.zeros((len(imgs), len(kps[0]), 2), dtype=np.float)\n",
    "    \n",
    "    #\n",
    "    # FLANN parameters\n",
    "    #\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    for kp_index, (desc, kp) in enumerate(zip(descs[1:], kps[1:])):\n",
    "        matches = flann.knnMatch(descs[0].astype(np.float32), desc.astype(np.float32), k=2)\n",
    "        \n",
    "        idx_filtered = []\n",
    "        for i, (m, n) in enumerate(matches):\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                idx_filtered.append(i)\n",
    "\n",
    "        if len(idx_filtered) < 4:\n",
    "            continue\n",
    "        \n",
    "        src_pts = np.float32([kps[0][matches[i][0].trainIdx].pt for i in idx_filtered]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([kp[matches[i][0].queryIdx].pt for i in idx_filtered]).reshape(-1,1,2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        idx_filtered = [i for i, m in zip(idx_filtered, mask.ravel()) if m]\n",
    "\n",
    "        kp_mask[0, idx_filtered] = 1\n",
    "        kp_coords[0, idx_filtered, :] = np.squeeze(src_pts[mask.astype(np.bool), :])\n",
    "\n",
    "        kp_mask[kp_index+1, idx_filtered] = 1\n",
    "        kp_coords[kp_index+1, idx_filtered, :] = np.squeeze(dst_pts[mask.astype(np.bool), :])\n",
    "        \n",
    "    return kp_mask, kp_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kp_mask, kps = match(imgs, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vmask = kp_mask[:, np.nonzero(kp_mask.sum(axis=0))[0]]\n",
    "vmask = np.ascontiguousarray(vmask.T).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measures = kps[:, np.nonzero(kp_mask.sum(axis=0))[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "J, I = np.nonzero(vmask)\n",
    "measures = measures[I, J]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = np.ascontiguousarray(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A, B = pba.run_pba(None, None, measures, vmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan],\n",
       "       [ 999.99993896,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,    0.        ,    0.        ,\n",
       "           0.        ,    1.        ,           nan,           nan,\n",
       "                  nan]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quaternions as qua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cameras = []\n",
    "with open('cams.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = np.fromstring(line.strip(), sep=' ')\n",
    "        f = np.array([a[0]])\n",
    "        q = a[10:14]\n",
    "        T = a[14:]\n",
    "        R = np.array(qua.Quaternion(*q.tolist()).asRotationMatrix())\n",
    "        cameras.append(np.concatenate((f, R.ravel(), T.ravel())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cameras = np.concatenate(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "measurements = []\n",
    "vi = []\n",
    "vj = []\n",
    "j = 0\n",
    "with open('pts.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = np.fromstring(line.strip(), sep=' ')\n",
    "        points.append(a[:3])\n",
    "        app = int(a[3])\n",
    "        for i in range(app):\n",
    "            vi.append(int(a[4+i*3]))\n",
    "            vj.append(j)\n",
    "            measurements.append(a[5+i*3:7+i*3])\n",
    "        j += 1\n",
    "\n",
    "vmask = np.zeros((len(points), 3), dtype=np.uint8)\n",
    "vmask[vj, vi] = 1\n",
    "\n",
    "points = np.concatenate(points)\n",
    "measurements = np.concatenate(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A, B = pba.run_pba(cameras, points, measurements, vmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.76290234e+03,  -3.25603217e-01,   6.38462827e-02,\n",
       "         -3.52472663e-01,   5.46009958e-01,   8.27237964e-01,\n",
       "         -1.06706157e-01,   7.71915615e-01,  -5.58210552e-01,\n",
       "         -6.44628406e-01,  -4.38879341e-01,  -2.93108344e-01,\n",
       "         -1.27592385e+00],\n",
       "       [  8.12118591e+02,  -4.38807875e-01,   1.13957167e-01,\n",
       "          3.04009706e-01,  -6.10692024e-01,   6.89808071e-01,\n",
       "         -2.74147749e-01,  -6.59154594e-01,  -7.14954734e-01,\n",
       "         -6.03262305e-01,  -4.23521362e-02,  -4.43524212e-01,\n",
       "         -8.23009431e-01],\n",
       "       [  4.24639302e-06,   2.91910261e-01,   9.04538691e-01,\n",
       "          3.10802847e-01,  -9.39500809e-01,   3.32074910e-01,\n",
       "         -8.40545967e-02,  -1.79240301e-01,  -2.67462879e-01,\n",
       "          9.46750402e-01,   3.72451757e+12,   4.66002379e+12,\n",
       "          2.85575950e+06]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.58761233e-01,  -6.03281036e-02,  -9.30928767e-01],\n",
       "       [  1.27083763e-01,  -4.91583981e-02,  -9.39415812e-01],\n",
       "       [  2.35567894e-02,   2.20771981e-04,  -9.93594825e-01],\n",
       "       ..., \n",
       "       [  8.10253620e-02,   2.84893904e-02,  -5.85538685e-01],\n",
       "       [  8.13209787e-02,   3.07266116e-02,  -5.87912083e-01],\n",
       "       [  8.14358145e-02,   3.30847949e-02,  -5.90292096e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
